{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4adb1e-6a3f-4783-990a-ed816b5b38e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import base64\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b0767c-8f74-45ec-9052-d800f6b950d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import PyPDF2\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0275684-b46d-4e01-b8bb-aadd9af3ee9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o diretório onde o módulo conexoes.py está localizado\n",
    "caminho_para_conexoes = '/Users/alexandreloureiro/bb/mefis/pln'\n",
    "\n",
    "# Adicionando o caminho ao sys.path\n",
    "if caminho_para_conexoes not in sys.path:\n",
    "    sys.path.append(caminho_para_conexoes)\n",
    "\n",
    "# Importando a função postgres do módulo conexoes\n",
    "from conexoes import postgres\n",
    "\n",
    "# Conectando ao banco de dados\n",
    "conn, engine = postgres()\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3156367-d627-4b63-9140-b37b7c4e5c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# Caminho para o arquivo PDF\n",
    "pdf_path = '/Users/alexandreloureiro/bb/mefis/estudo_risco.pdf'\n",
    "\n",
    "# Caminho para o arquivo de saída\n",
    "output_path = 'relatorio.txt'\n",
    "\n",
    "# Abrir o arquivo PDF\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    # Inicializar uma lista para armazenar o texto de cada página\n",
    "    paginas_texto = []\n",
    "    \n",
    "    # Iterar por todas as páginas\n",
    "    for page_num, page in enumerate(pdf.pages, start=1):\n",
    "        print(f'Processando página {page_num} de {len(pdf.pages)}...')\n",
    "        \n",
    "        # Extrair o texto da página, mantendo o layout\n",
    "        texto = page.extract_text(x_tolerance=1, y_tolerance=1)\n",
    "        \n",
    "        if texto:\n",
    "            paginas_texto.append(texto)\n",
    "        else:\n",
    "            print(f'Aviso: Nenhum texto encontrado na página {page_num}.')\n",
    "\n",
    "# Unir o texto de todas as páginas\n",
    "texto_completo = '\\n\\n'.join(paginas_texto)\n",
    "\n",
    "# Salvar o texto no arquivo 'relatorio.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(texto_completo)\n",
    "\n",
    "print(f'\\nExtração concluída. O texto foi salvo em \"{output_path}\".')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22148c57-b0ba-4555-b14d-84b9847f8f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "# Caminho para o arquivo PDF\n",
    "pdf_path = '/Users/alexandreloureiro/bb/mefis/estudo_risco.pdf'\n",
    "\n",
    "# Caminho para o arquivo de saída\n",
    "output_path = 'relatorio2.txt'\n",
    "\n",
    "# Abrir o arquivo PDF em modo de leitura binária\n",
    "with open(pdf_path, 'rb') as pdf_file:\n",
    "    # Criar um objeto leitor do PDF\n",
    "    pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "    \n",
    "    # Inicializar uma lista para armazenar o texto de cada página\n",
    "    paginas_texto = []\n",
    "    \n",
    "    # Iterar por todas as páginas do PDF\n",
    "    for page_num in range(len(pdf_reader.pages)):\n",
    "        print(f'Processando página {page_num + 1} de {len(pdf_reader.pages)}...')\n",
    "        # Obter a página atual\n",
    "        page = pdf_reader.pages[page_num]\n",
    "        # Extrair o texto da página\n",
    "        texto = page.extract_text()\n",
    "        if texto:\n",
    "            paginas_texto.append(texto)\n",
    "        else:\n",
    "            print(f'Aviso: Nenhum texto encontrado na página {page_num + 1}.')\n",
    "\n",
    "# Unir o texto de todas as páginas\n",
    "texto_completo = '\\n\\n'.join(paginas_texto)\n",
    "\n",
    "# Salvar o texto no arquivo 'relatorio2.txt'\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(texto_completo)\n",
    "\n",
    "print(f'\\nExtração concluída. O texto foi salvo em \"{output_path}\".')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2d1f5-e1f0-44f7-9ff4-ed23b545fe75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "# Lista de caminhos para os arquivos PDF\n",
    "pdf_files = [\n",
    "    '/Users/alexandreloureiro/bb/mefis/estudo_risco.pdf',\n",
    "    '/Users/alexandreloureiro/bb/mefis/estrategia.pdf',\n",
    "    '/Users/alexandreloureiro/bb/mefis/notas/ecbb.pdf',\n",
    "    '/Users/alexandreloureiro/bb/mefis/notas/mrld_5.pdf',\n",
    "]\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    # Verificar se o arquivo existe\n",
    "    if not os.path.isfile(pdf_path):\n",
    "        print(f'Arquivo não encontrado: {pdf_path}')\n",
    "        continue\n",
    "\n",
    "    # Obter o nome base do arquivo (sem o caminho completo)\n",
    "    base_name = os.path.basename(pdf_path)\n",
    "    # Remover a extensão '.pdf' do nome base\n",
    "    file_name_no_ext = os.path.splitext(base_name)[0]\n",
    "    # Criar o nome do arquivo de saída\n",
    "    output_path = f'rel_temp_{file_name_no_ext}.txt'\n",
    "\n",
    "    print(f'Processando o arquivo: {pdf_path}')\n",
    "    # Extrair todo o texto do PDF\n",
    "    texto_completo = extract_text(pdf_path)\n",
    "\n",
    "    # Remover múltiplas quebras de linha consecutivas\n",
    "    texto_limpo = re.sub(r'\\n\\s*\\n+', '\\n\\n', texto_completo)\n",
    "\n",
    "    # Remover múltiplos espaços dentro das linhas\n",
    "    texto_limpo = re.sub(r'[ ]{2,}', ' ', texto_limpo)\n",
    "\n",
    "    # Salvar o texto no arquivo de saída\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(texto_limpo)\n",
    "\n",
    "    print(f'Extração concluída para \"{pdf_path}\". O texto foi salvo em \"{output_path}\".\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9684a7f6-b69f-484c-8713-15ba26715a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de caminhos para os arquivos PDF\n",
    "pdf_files = [\n",
    "    '/Users/arquivo.pdf',\n",
    "    '/Users/arquivo.pdf',\n",
    "    '/Users/arquivo.pdf',\n",
    "    '/Users/arquivo.pdf',\n",
    "]\n",
    "\n",
    "# Definir o modelo e obter o codificador apropriado\n",
    "modelo = 'gpt-4'\n",
    "try:\n",
    "    encoding = tiktoken.encoding_for_model(modelo)\n",
    "except KeyError:\n",
    "    print(f'Modelo \"{modelo}\" não encontrado. Usando codificação padrão \"cl100k_base\".')\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "# Lista para armazenar os dados\n",
    "dados = []\n",
    "\n",
    "for pdf_path in pdf_files:\n",
    "    # Verificar se o arquivo existe\n",
    "    if not os.path.isfile(pdf_path):\n",
    "        print(f'Arquivo não encontrado: {pdf_path}')\n",
    "        continue\n",
    "\n",
    "    # Obter o nome base do arquivo (sem o caminho completo)\n",
    "    base_name = os.path.basename(pdf_path)\n",
    "    # Remover a extensão '.pdf' do nome base\n",
    "    file_name_no_ext = os.path.splitext(base_name)[0]\n",
    "\n",
    "    print(f'Processando o arquivo: {pdf_path}')\n",
    "    # Extrair todo o texto do PDF\n",
    "    texto_completo = extract_text(pdf_path)\n",
    "\n",
    "    # Remover múltiplas quebras de linha consecutivas\n",
    "    texto_limpo = re.sub(r'\\n\\s*\\n+', '\\n\\n', texto_completo)\n",
    "\n",
    "    # Remover múltiplos espaços dentro das linhas\n",
    "    texto_limpo = re.sub(r'[ ]{2,}', ' ', texto_limpo)\n",
    "\n",
    "    # Remover espaços em branco no início e no fim das linhas\n",
    "    linhas = texto_limpo.split('\\n')\n",
    "    linhas = [linha.strip() for linha in linhas]\n",
    "\n",
    "    # Remover linhas completamente vazias\n",
    "    linhas = [linha for linha in linhas if linha != '']\n",
    "\n",
    "    # Reunir as linhas em um único texto\n",
    "    texto_final = '\\n'.join(linhas)\n",
    "\n",
    "    # Calcular o número de tokens usando tiktoken\n",
    "    tokens = encoding.encode(texto_final)\n",
    "    numero_de_tokens = len(tokens)\n",
    "\n",
    "    # Adicionar os dados à lista\n",
    "    dados.append({\n",
    "        'path': pdf_path,\n",
    "        'filename': base_name,\n",
    "        'extracted_text': texto_final,\n",
    "        'numero_de_tokens': numero_de_tokens\n",
    "    })\n",
    "\n",
    "    print(f'Extração concluída para \"{pdf_path}\". Número de tokens: {numero_de_tokens}\\n')\n",
    "\n",
    "# Criar o dataframe\n",
    "df = pd.DataFrame(dados, columns=['path', 'filename', 'extracted_text', 'numero_de_tokens'])\n",
    "\n",
    "# Exibir o dataframe\n",
    "print(df)\n",
    "\n",
    "# Opcional: Salvar o dataframe em um arquivo CSV ou Excel\n",
    "# df.to_csv('textos_extraidos_com_tokens.csv', index=False)\n",
    "# df.to_excel('textos_extraidos_com_tokens.xlsx', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9428f4-1b01-4cb3-b3b0-0252611f9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178dcbca-55b0-44de-aceb-c2a0541afd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'gpt-4'\n",
    "encoding = tiktoken.encoding_for_model(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd5adf3-e0b3-49d9-a2d0-be1833e3c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = encoding.encode(texto_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b99978-ad07-41ec-9ac8-375fdd2c9e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aa2b65-6cc8-4687-8e2d-bae2f557a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'O número de tokens para o modelo {modelo} é: {numero_de_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3d42c-e655-4438-88e9-b6aedc886d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "from pdfminer.pdfparser import PDFSyntaxError\n",
    "import re\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def limpar_texto(texto):\n",
    "    \"\"\"\n",
    "    Função para limpar e formatar o texto extraído do PDF\n",
    "    \"\"\"\n",
    "    # Remove caracteres especiais e formata o texto\n",
    "    texto = re.sub(r'\\f', '', texto)  # Remove form feeds\n",
    "    texto = re.sub(r'[ \\t]+', ' ', texto)  # Remove múltiplos espaços e tabs\n",
    "    texto = re.sub(r'\\n\\s*\\n+', '\\n\\n', texto)  # Remove múltiplas quebras de linha\n",
    "    texto = re.sub(r'_{3,}', '_____', texto)  # Padroniza linhas de underscore\n",
    "    texto = re.sub(r'\\.{3,}', '...', texto)  # Padroniza reticências\n",
    "    \n",
    "    # Remove espaços antes de pontuação\n",
    "    texto = re.sub(r'\\s+([.,;!?])', r'\\1', texto)\n",
    "    \n",
    "    # Remove linhas que contêm apenas números de página\n",
    "    texto = re.sub(r'^\\s*\\d+\\s*$', '', texto, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove espaços no início e fim de cada linha\n",
    "    linhas = [linha.strip() for linha in texto.split('\\n')]\n",
    "    texto = '\\n'.join(linhas)\n",
    "    \n",
    "    # Remove linhas vazias consecutivas mantendo no máximo uma\n",
    "    texto = re.sub(r'\\n{3,}', '\\n\\n', texto)\n",
    "    \n",
    "    return texto.strip()\n",
    "\n",
    "def extrair_texto_pdf(caminho_pdf, caminho_saida):\n",
    "    \"\"\"\n",
    "    Extrai e processa texto de um arquivo PDF\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Verifica se o arquivo existe\n",
    "        if not os.path.exists(caminho_pdf):\n",
    "            raise FileNotFoundError(f\"O arquivo '{caminho_pdf}' não foi encontrado.\")\n",
    "            \n",
    "        # Cria backup do arquivo de saída se ele já existir\n",
    "        if os.path.exists(caminho_saida):\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            backup_path = f\"{caminho_saida}.{timestamp}.bak\"\n",
    "            os.rename(caminho_saida, backup_path)\n",
    "            print(f\"Backup do arquivo anterior criado: {backup_path}\")\n",
    "        \n",
    "        print(\"Extraindo texto do PDF...\")\n",
    "        texto_completo = extract_text(caminho_pdf)\n",
    "        \n",
    "        print(\"Limpando e formatando o texto...\")\n",
    "        texto_limpo = limpar_texto(texto_completo)\n",
    "        \n",
    "        # Adiciona informações do processamento\n",
    "        cabecalho = f\"\"\"# Texto extraído do arquivo: {os.path.basename(caminho_pdf)}\n",
    "# Data de extração: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "# Processado com pdfminer.six\n",
    "{'='*80}\\n\\n\"\"\"\n",
    "        \n",
    "        texto_final = cabecalho + texto_limpo\n",
    "        \n",
    "        # Salva o texto processado\n",
    "        with open(caminho_saida, 'w', encoding='utf-8') as f:\n",
    "            f.write(texto_final)\n",
    "            \n",
    "        # Estatísticas do processamento\n",
    "        total_caracteres = len(texto_final)\n",
    "        total_palavras = len(texto_final.split())\n",
    "        total_linhas = len(texto_final.splitlines())\n",
    "        \n",
    "        print(f\"\\nProcessamento concluído com sucesso!\")\n",
    "        print(f\"Arquivo salvo em: {caminho_saida}\")\n",
    "        print(f\"\\nEstatísticas:\")\n",
    "        print(f\"- Total de caracteres: {total_caracteres:,}\")\n",
    "        print(f\"- Total de palavras: {total_palavras:,}\")\n",
    "        print(f\"- Total de linhas: {total_linhas:,}\")\n",
    "        \n",
    "    except PDFSyntaxError:\n",
    "        print(\"Erro: O arquivo PDF está corrompido ou não pode ser lido.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Erro: Sem permissão para acessar ou criar o arquivo '{caminho_saida}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erro inesperado: {str(e)}\")\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "pdf_path = '/Users/alexandreloureiro/bb/mefis/estudo_risco.pdf'\n",
    "output_path = 'relatorio3.txt'\n",
    "\n",
    "# Executa a extração\n",
    "extrair_texto_pdf(pdf_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbfec40-0ec9-448e-848b-434005dfadd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas necessárias\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "def limpar_texto(texto):\n",
    "    \"\"\"\n",
    "    Limpa o texto removendo linhas em branco extras e espaços desnecessários.\n",
    "    \n",
    "    Args:\n",
    "        texto (str): Texto a ser limpo\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto limpo\n",
    "    \"\"\"\n",
    "    # Remove caracteres especiais e espaços extras\n",
    "    texto = re.sub(r'_+', '_', texto)  # Substitui múltiplos underscores por um único\n",
    "    texto = re.sub(r'\\s*\\n\\s*\\n\\s*', '\\n\\n', texto)  # Substitui múltiplas linhas em branco por uma única\n",
    "    texto = re.sub(r'\\s+', ' ', texto)  # Substitui múltiplos espaços por um único\n",
    "    texto = texto.strip()  # Remove espaços no início e fim\n",
    "    \n",
    "    # Divide o texto em linhas\n",
    "    linhas = texto.split('\\n')\n",
    "    \n",
    "    # Remove linhas que só contêm espaços ou caracteres especiais\n",
    "    linhas = [linha.strip() for linha in linhas if linha.strip() and not linha.strip().startswith('_' * 10)]\n",
    "    \n",
    "    # Junta as linhas de volta com uma quebra de linha dupla\n",
    "    return '\\n\\n'.join(linhas)\n",
    "\n",
    "def extrair_texto_pdf(caminho_pdf):\n",
    "    \"\"\"\n",
    "    Extrai texto de um arquivo PDF e limpa formatação extra.\n",
    "    \n",
    "    Args:\n",
    "        caminho_pdf (str): Caminho para o arquivo PDF\n",
    "        \n",
    "    Returns:\n",
    "        str: Texto extraído e limpo do PDF\n",
    "    \"\"\"\n",
    "    with open(caminho_pdf, 'rb') as arquivo:\n",
    "        leitor_pdf = PyPDF2.PdfReader(arquivo)\n",
    "        texto_completo = \"\"\n",
    "        \n",
    "        print(f\"Total de páginas no PDF: {len(leitor_pdf.pages)}\")\n",
    "        \n",
    "        for num_pagina, pagina in enumerate(leitor_pdf.pages, 1):\n",
    "            # Extrai o texto da página\n",
    "            texto_pagina = pagina.extract_text()\n",
    "            \n",
    "            # Limpa o texto da página\n",
    "            texto_pagina_limpo = limpar_texto(texto_pagina)\n",
    "            \n",
    "            # Adiciona cabeçalho da página e o texto limpo\n",
    "            texto_completo += f\"\\n=== Página {num_pagina} ===\\n\\n\"\n",
    "            texto_completo += texto_pagina_limpo + \"\\n\"\n",
    "        \n",
    "        # Limpa novamente o texto completo para garantir consistência\n",
    "        texto_completo = limpar_texto(texto_completo)\n",
    "        return texto_completo\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf15b54-edbc-4310-ba6f-382dfc56440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extrair e limpar o texto\n",
    "texto_extraido = extrair_texto_pdf(caminho_do_pdf)\n",
    "\n",
    "# Mostrar uma amostra do texto limpo\n",
    "print(\"\\nAmostra do texto limpo:\")\n",
    "print(texto_extraido[:500])\n",
    "\n",
    "# Salvar o texto limpo em um arquivo\n",
    "with open(\"texto_extraido_limpo.txt\", \"w\", encoding=\"utf-8\") as arquivo_texto:\n",
    "    arquivo_texto.write(texto_extraido)\n",
    "\n",
    "# Para visualizar de forma mais organizada no Jupyter\n",
    "from IPython.display import display, Markdown\n",
    "display(Markdown(texto_extraido))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582bd8b4-79ef-45a4-9060-b951326d1c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c57fb1-0ecd-45a7-897b-677eb9977d65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856db12-dd1b-4e6a-a47b-a199e755e018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517e1e3-f84f-4218-bc98-310fe980bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo os dados da tabela\n",
    "query = \"\"\"\n",
    "    SELECT cd_atvd, cd_rel_atvd, cd_tip_rel_atvd, cd_tip_est_rel, tx_rel_atvd,\n",
    "           cd_usu_rsp_rel, cd_uor_rsp_rel, ts_vld_rel, db2_generated_rowid_for_lobs,\n",
    "           nr_trabalho, tx_constatacao, rel_hash, rel_s_hash\n",
    "    FROM ptai.com_resultado_analise;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01b226c-50c8-4121-ac48-dbcaf164b4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb97feea-9dc4-44a7-9d3e-afc0fc13deb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se a coluna 'tx_rel_atvd_sem_html' existe; caso contrário, cria\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT column_name FROM information_schema.columns\n",
    "    WHERE table_schema = 'ptai' AND table_name = 'com_resultado_analise' AND column_name = 'tx_rel_atvd_sem_html';\n",
    "\"\"\")\n",
    "column_exists = cursor.fetchone()\n",
    "\n",
    "if not column_exists:\n",
    "    cursor.execute(\"\"\"\n",
    "        ALTER TABLE ptai.com_resultado_analise ADD COLUMN tx_rel_atvd_sem_html TEXT;\n",
    "    \"\"\")\n",
    "    conn.commit()\n",
    "\n",
    "cursor.execute(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS ptai.com_resultado_analise_imagens (\n",
    "        nr_trabalho INTEGER,\n",
    "        image_number INTEGER,\n",
    "        image_data BYTEA,\n",
    "        image_type TEXT,\n",
    "        path_imagem TEXT\n",
    "    );\n",
    "\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be50551a-e35f-4e64-b7ed-f4e06d2c8a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_row(row):\n",
    "    html_content = row['tx_rel_atvd']\n",
    "    nr_trabalho = row['nr_trabalho']\n",
    "\n",
    "    # Verifica se o conteúdo HTML é válido\n",
    "    if not isinstance(html_content, str):\n",
    "        return '', []\n",
    "\n",
    "    # Utiliza o BeautifulSoup para analisar o conteúdo HTML\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Extrai o texto puro, removendo todas as tags HTML\n",
    "    text_content = soup.get_text(separator='\\n')\n",
    "\n",
    "    # Contador para nomear as imagens na ordem em que aparecem\n",
    "    image_counter = 1\n",
    "\n",
    "    images_list = []\n",
    "\n",
    "    # Encontra todas as tags <img> no conteúdo HTML\n",
    "    for img_tag in soup.find_all('img'):\n",
    "        img_src = img_tag.get('src', '')\n",
    "        # Verifica se o 'src' é um data URL com imagem em base64\n",
    "        data_url_match = re.match(r'data:image/(\\w+);base64,(.*)', img_src)\n",
    "        if data_url_match:\n",
    "            img_type = data_url_match.group(1)  # Obtém o tipo da imagem (jpeg, png, etc.)\n",
    "            base64_data = data_url_match.group(2)  # Obtém os dados base64\n",
    "            # Decodifica os dados base64 para bytes de imagem\n",
    "            try:\n",
    "                img_data = base64.b64decode(base64_data)\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao decodificar imagem base64 para nr_trabalho {nr_trabalho}: {e}\")\n",
    "                continue\n",
    "            # Define o nome e o caminho do arquivo de imagem\n",
    "            image_filename = f\"{nr_trabalho}_{image_counter}.{img_type}\"\n",
    "            image_path = os.path.join('imagem_relatorio', image_filename)\n",
    "            # Salva a imagem no diretório especificado\n",
    "            with open(image_path, 'wb') as f:\n",
    "                f.write(img_data)\n",
    "            # Armazena os dados da imagem na lista, incluindo o caminho da imagem\n",
    "            images_list.append((nr_trabalho, image_counter, psycopg2.Binary(img_data), img_type, image_path))\n",
    "            # Incrementa o contador de imagens\n",
    "            image_counter += 1\n",
    "\n",
    "    # Retorna o texto puro e a lista de imagens\n",
    "    return text_content, images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10396d66-03e5-406d-b26f-f3b02f772c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica se a pasta 'imagem_relatorio' existe; caso contrário, cria\n",
    "if not os.path.exists('imagem_relatorio'):\n",
    "    os.makedirs('imagem_relatorio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c22b08-7f67-45d6-8130-1debe99cc312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a função a cada linha do DataFrame para criar a nova coluna 'tx_rel_atvd_sem_html' e coletar as imagens\n",
    "result = df.apply(process_row, axis=1, result_type='expand')\n",
    "df['tx_rel_atvd_sem_html'] = result[0]\n",
    "df['images'] = result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa82a90-d6cb-400e-b2fa-09fa6a6ad25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coleta todas as imagens para inserir no banco de dados\n",
    "images_to_insert = []\n",
    "for images_list in df['images']:\n",
    "    images_to_insert.extend(images_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e46f17-7653-4161-9988-4db13435d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insere as imagens no banco de dados\n",
    "if images_to_insert:\n",
    "    sql_insert_images = \"\"\"\n",
    "        INSERT INTO ptai.com_resultado_analise_imagens (nr_trabalho, image_number, image_data, image_type, path_imagem)\n",
    "        VALUES (%s, %s, %s, %s, %s);\n",
    "    \"\"\"\n",
    "    cursor.executemany(sql_insert_images, images_to_insert)\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5c894-2364-454a-89f1-28c29e9e7772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a coluna 'images' do DataFrame\n",
    "df.drop('images', axis=1, inplace=True)\n",
    "\n",
    "# Prepara os dados para atualizar a tabela original\n",
    "data_to_update = list(zip(df['tx_rel_atvd_sem_html'], df['cd_atvd']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55836a69-0718-43be-a330-ac9a63cbcd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualiza a tabela original com o novo texto\n",
    "sql_update = \"\"\"\n",
    "    UPDATE ptai.com_resultado_analise\n",
    "    SET tx_rel_atvd_sem_html = %s\n",
    "    WHERE cd_atvd = %s;\n",
    "\"\"\"\n",
    "\n",
    "cursor.executemany(sql_update, data_to_update)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc2541-70c2-4045-a24b-b5319418596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha o cursor e a conexão\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fddb71-2210-4835-88df-1cea7372f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reabrir a conexão ao banco de dados\n",
    "conn, engine = postgres()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Consulta para recuperar as imagens\n",
    "query_images = \"\"\"\n",
    "    SELECT nr_trabalho, image_number, image_data, image_type\n",
    "    FROM ptai.com_resultado_analise_imagens;\n",
    "\"\"\"\n",
    "\n",
    "df_images = pd.read_sql(query_images, conn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb510912-f668-4d6d-a391-5191fb9eb1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Função para exibir uma imagem\n",
    "def display_image(row):\n",
    "    img_data = row['image_data']\n",
    "    img_type = row['image_type']\n",
    "    # Converter os dados binários em uma imagem PIL\n",
    "    image = Image.open(BytesIO(img_data))\n",
    "    # Exibir a imagem\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"nr_trabalho: {row['nr_trabalho']}, image_number: {row['image_number']}\")\n",
    "    plt.show()\n",
    "\n",
    "# Exibir todas as imagens\n",
    "for index, row in df_images.iterrows():\n",
    "    display_image(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66dcc6c-22ce-47d8-84ac-895628586030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
