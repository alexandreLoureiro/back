# Importar bibliotecas necessárias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split

# Definir semente para reprodutibilidade
np.random.seed(42)

# Excluir a coluna 'QT_RCLM_CLI' das variáveis preditivas
variaveis_preditivas = exercicio10b.columns.drop('QT_RCLM_CLI')[:21]

# Criar os DataFrames X (variáveis preditoras) e y (variável alvo)
X = exercicio10b[variaveis_preditivas]
y = exercicio10c['IN_EVS']

# Divisão dos dados em treino e teste, com 30% para teste
exercicio11a, exercicio11b, exercicio11c, exercicio11d = train_test_split(
    X, y, test_size=0.30, random_state=42, shuffle=True
)

# Resetar os índices para evitar problemas futuros
exercicio11a.reset_index(drop=True, inplace=True)
exercicio11b.reset_index(drop=True, inplace=True)
exercicio11c.reset_index(drop=True, inplace=True)
exercicio11d.reset_index(drop=True, inplace=True)

# Garantir que as variáveis estejam no formato de DataFrame
exercicio11a = pd.DataFrame(exercicio11a, columns=variaveis_preditivas)
exercicio11b = pd.DataFrame(exercicio11b, columns=variaveis_preditivas)
exercicio11c = pd.DataFrame(exercicio11c, columns=['IN_EVS'])
exercicio11d = pd.DataFrame(exercicio11d, columns=['IN_EVS'])


# Importar bibliotecas necessárias
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import f1_score

# 1. Variáveis preditivas e alvo (do exercício 11)
X_train = exercicio11a.copy()
X_test = exercicio11b.copy()
y_train = exercicio11c.values.ravel()
y_test = exercicio11d.values.ravel()

# 2. Escalonamento dos dados (apenas para modelos que necessitam)
escalonador = StandardScaler()

# Ajustar o escalonador nos dados de treino e aplicar nos dados de teste
X_train_escalado = escalonador.fit_transform(X_train)
X_test_escalado = escalonador.transform(X_test)

# 3. Criação dos modelos
exercicio12e = LogisticRegression(random_state=42, max_iter=1000)
exercicio12f = DecisionTreeClassifier(random_state=42)
exercicio12g = SVC(random_state=42)

# 4. Treinamento dos modelos
# 4.1. Regressão Logística e SVM com dados escalonados
exercicio12e.fit(X_train_escalado, y_train)
exercicio12g.fit(X_train_escalado, y_train)

# 4.2. Árvore de Decisão com dados originais (sem escalonamento)
exercicio12f.fit(X_train, y_train)

# 5. Realizando previsões
# 5.1. Regressão Logística
y_pred_logreg = exercicio12e.predict(X_test_escalado)

# 5.2. Árvore de Decisão
y_pred_tree = exercicio12f.predict(X_test)

# 5.3. SVM
y_pred_svm = exercicio12g.predict(X_test_escalado)

# 6. Calculando os F1-scores
exercicio12a = round(f1_score(y_test, y_pred_logreg), 3)
exercicio12b = round(f1_score(y_test, y_pred_tree), 3)
exercicio12c = round(f1_score(y_test, y_pred_svm), 3)

# 7. Identificando o melhor modelo
f1_scores = {
    'LogisticRegression': exercicio12a,
    'DecisionTreeClassifier': exercicio12b,
    'SVC': exercicio12c
}
melhor_modelo_nome = max(f1_scores, key=f1_scores.get)
modelos = {
    'LogisticRegression': exercicio12e,
    'DecisionTreeClassifier': exercicio12f,
    'SVC': exercicio12g
}
exercicio12d = modelos[melhor_modelo_nome]
# 8. Exibindo os resultados
print(f"F1-score Regressão Logística (exercicio12a): {exercicio12a}")
print(f"F1-score Árvore de Decisão (exercicio12b): {exercicio12b}")
print(f"F1-score SVM (exercicio12c): {exercicio12c}")
print(f"Melhor modelo (exercicio12d): {type(exercicio12d).__name__}")





# Supondo que o exercício 14 envolve alguma análise com os dados de treino

# Utilize X_train em vez de X_train_imputado
# Por exemplo, se estiver aplicando alguma técnica de balanceamento ou transformação:

from imblearn.over_sampling import SMOTE

# Balanceamento dos dados de treino
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# Continuar com o código normalmente, utilizando X_train_bal e y_train_bal




# Importar bibliotecas necessárias
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import f1_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay

# 1. Balanceamento dos dados de treino
smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

# 2. Escalonamento dos dados balanceados (para modelos que precisam)
escalonador_smote = StandardScaler()
X_train_bal_escalado = escalonador_smote.fit_transform(X_train_bal)

# 3. Definição dos modelos
logreg = LogisticRegression(random_state=42, max_iter=1000)
clf = DecisionTreeClassifier(random_state=42)
svc = SVC(random_state=42)

# 4. Treinamento dos modelos com dados balanceados
# 4.1. Regressão Logística e SVM com dados escalonados
logreg.fit(X_train_bal_escalado, y_train_bal)
svc.fit(X_train_bal_escalado, y_train_bal)

# 4.2. Árvore de Decisão com dados originais (não escalonados)
clf.fit(X_train_bal, y_train_bal)

# 5. Realizando previsões
# 5.1. Regressão Logística
y_pred_logreg_smote = logreg.predict(X_test_escalado)

# 5.2. Árvore de Decisão
y_pred_clf_smote = clf.predict(X_test)

# 5.3. SVM
y_pred_svm_smote = svc.predict(X_test_escalado)

# 6. Calculando os F1-scores
exercicio15a = round(f1_score(y_test, y_pred_logreg_smote), 3)
exercicio15b = round(f1_score(y_test, y_pred_clf_smote), 3)
exercicio15c = round(f1_score(y_test, y_pred_svm_smote), 3)

# 7. Identificando o melhor modelo
f1_scores_smote = {
    'LogisticRegression': exercicio15a,
    'DecisionTreeClassifier': exercicio15b,
    'SVC': exercicio15c
}

melhor_modelo_nome_smote = max(f1_scores_smote, key=f1_scores_smote.get)
modelos_smote = {
    'LogisticRegression': logreg,
    'DecisionTreeClassifier': clf,
    'SVC': svc
}

exercicio15d = modelos_smote[melhor_modelo_nome_smote]

# 8. Exibindo os resultados
print(f"F1-score Regressão Logística (exercicio15a): {exercicio15a}")
print(f"F1-score Árvore de Decisão (exercicio15b): {exercicio15b}")
print(f"F1-score SVM (exercicio15c): {exercicio15c}")
print(f"Melhor modelo (exercicio15d): {type(exercicio15d).__name__}")

# 9. Criação da Matriz de Confusão para o Melhor Modelo Balanceado
# 9.1. Escolhendo o conjunto de teste apropriado
if isinstance(exercicio15d, (LogisticRegression, SVC)):
    X_test_input_smote = X_test_escalado
elif isinstance(exercicio15d, DecisionTreeClassifier):
    X_test_input_smote = X_test
else:
    raise ValueError("Modelo desconhecido.")

# 9.2. Realizando previsões com o melhor modelo balanceado
y_pred_melhor_smote = exercicio15d.predict(X_test_input_smote)

# 9.3. Calculando a matriz de confusão
cm_smote = confusion_matrix(y_test, y_pred_melhor_smote)
print("Matriz de Confusão:")
print(cm_smote)

# 9.4. Extraindo os valores TN, FP, FN, TP
TN_smote, FP_smote, FN_smote, TP_smote = cm_smote.ravel()
exercicio15e = FP_smote
exercicio15f = FN_smote

# 9.5. Exibindo os resultados
print(f"Falsos Positivos (exercicio15e): {exercicio15e}")
print(f"Falsos Negativos (exercicio15f): {exercicio15f}")

# 9.6. Calculando métricas adicionais
precisao_smote = precision_score(y_test, y_pred_melhor_smote)
recall_smote = recall_score(y_test, y_pred_melhor_smote)





# Importar bibliotecas necessárias
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import make_scorer, f1_score

# Definir a métrica de avaliação como F1-score
f1_scorer = make_scorer(f1_score)

# 1. Preparação dos dados
# Usar X_train e y_train definidos no exercício 12
# Como a Validação Cruzada envolve múltiplas divisões dos dados, vamos combinar X_train e X_test
X_full = pd.concat([X_train, X_test], axis=0).reset_index(drop=True)
y_full = np.concatenate([y_train, y_test], axis=0)

# 2. Escalonamento dos dados para modelos que necessitam
escalonador = StandardScaler()
X_full_escalado = escalonador.fit_transform(X_full)

# 3. Definição dos modelos
modelo_logreg = LogisticRegression(random_state=42, max_iter=1000)
modelo_tree = DecisionTreeClassifier(random_state=42)
modelo_svm = SVC(random_state=42)

# 4. Avaliação dos modelos com Validação Cruzada
# 4.1. Regressão Logística
scores_logreg = cross_val_score(
    modelo_logreg, X_full_escalado, y_full, cv=5, scoring=f1_scorer
)
media_logreg = round(scores_logreg.mean(), 3)
desvio_logreg = round(scores_logreg.std(), 3)

# 4.2. Árvore de Decisão
scores_tree = cross_val_score(
    modelo_tree, X_full, y_full, cv=5, scoring=f1_scorer
)
media_tree = round(scores_tree.mean(), 3)
desvio_tree = round(scores_tree.std(), 3)

# 4.3. SVM
scores_svm = cross_val_score(
    modelo_svm, X_full_escalado, y_full, cv=5, scoring=f1_scorer
)
media_svm = round(scores_svm.mean(), 3)
desvio_svm = round(scores_svm.std(), 3)

# 5. Exibindo os resultados
print("Desempenho dos modelos com Validação Cruzada:")
print(f"Regressão Logística - Média F1-score: {media_logreg}, Desvio Padrão: {desvio_logreg}")
print(f"Árvore de Decisão - Média F1-score: {media_tree}, Desvio Padrão: {desvio_tree}")
print(f"SVM - Média F1-score: {media_svm}, Desvio Padrão: {desvio_svm}")

# 6. Identificando o melhor modelo
medias = {
    'LogisticRegression': media_logreg,
    'DecisionTreeClassifier': media_tree,
    'SVC': media_svm
}
melhor_modelo_nome = max(medias, key=medias.get)
print(f"O melhor modelo é: {melhor_modelo_nome}")



f1_smote = f1_score(y_test, y_pred_melhor_smote)

print(f"Precisão: {precisao_smote:.4f}")
print(f"Recall: {recall_smote:.4f}")
print(f"F1 Score: {f1_smote:.4f}")

# 9.7. Visualizando a matriz de confusão
disp_smote = ConfusionMatrixDisplay(confusion_matrix=cm_smote, display_labels=['Não Churn', 'Churn'])
disp_smote.plot()

======================


Exercício 14 - Balanceamento dos dados com SMOTE
Faça o oversampling dos dados produzidos no exercício 11 utilizando a técnica SMOTE, porém, de forma a não enviesar os dados de teste.

O objeto SMOTE deve ser criado numa variável chamada smt.

Use random_state=42 no SMOTE

O resultado do balanceamento dos dados de treinamento deve ser salvo nas variáveis exercicio14a e exercicio14b.

exercicio14a : Dados de treino para as variáveis preditoras (X)
exercicio14b : Dados de treino para a variável alvo (y)
Crie as variáveis exercicio14c, exercicio14d, exercicio14e e exercicio14f:

Guarde as quantidades de amostras das classe 0 e classe 1 ANTES a utilização do SMOTE nas variáveis exercicio14c e exercicio14d.
Guarde as quantidades de amostras das classe 0 e classe 1 APÓS a utilização do SMOTE nas variáveis exercicio14e e exercicio14f.
Abaixo temos um exemplo fictício de como ficaria o print da quantidade de amostras por classe ANTES da aplicação do SMOTE. Na sequência os prints dos valores do exemplo nas variáveis exercicio14c e exercicio14d.

0.0    4533
1.0    1767
Name: IN_EVS, dtype: int64
print(exercicio14c)
OUTPUT: 4533

print(exercicio14d)
OUTPUT: 1767
Abaixo temos um exemplo fictício de como ficaria o print da quantidade de amostras por classe APÓS a aplicação do SMOTE. Na sequência os prints dos valores do exemplo nas variáveis exercicio14e e exercicio14f.

0.0    4533
1.0    4533
Name: IN_EVS, dtype: int64
print(exercicio14e)
OUTPUT: 4533

print(exercicio14f)
OUTPUT: 4533




